{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "# client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_question = {\n",
    "    \"section_name\": \"self-check-questions\",\n",
    "    \"section_text\": \"Question: \\n2. \\n\\n  What are the drawbacks to analyzing the global economy on a regional basis?\\n  \\n Answer: 2. \\n\\n  A region can have some of high-income countries and some of the low-income countries. Aggregating per capita real GDP will vary widely across countries within a region, so aggregating data for a region has little meaning. For example, if you were to compare per capital real GDP for the United States, Canada, Haiti, and Honduras, it looks much different than if you looked at the same data for North America as a whole. Thus, regional comparisons are broad-based and may not adequately capture an individual country’s economic attributes.\\n  \\n\",\n",
    "    \"chapter_name\": \"32-self-check-questions\",\n",
    "    \"textbook_name\": \"principles-economics-3e\",\n",
    "    \"chapter_url\": \"https://openstax.org/books/principles-economics-3e/pages/32-self-check-questions\",\n",
    "    \"question\": \"\\n2. \\n\\n  What are the drawbacks to analyzing the global economy on a regional basis?\\n  \\n\",\n",
    "    \"answer\": \"2. \\n\\n  A region can have some of high-income countries and some of the low-income countries. Aggregating per capita real GDP will vary widely across countries within a region, so aggregating data for a region has little meaning. For example, if you were to compare per capital real GDP for the United States, Canada, Haiti, and Honduras, it looks much different than if you looked at the same data for North America as a whole. Thus, regional comparisons are broad-based and may not adequately capture an individual country’s economic attributes.\\n  \\n\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extract_features = f\"\"\"\n",
    "Question: {current_question['question']}\n",
    "Gold Answer: {current_question['answer']}\n",
    "Your task: Think about the question and understand the answer first, then extract complete bullet points that are keyfeatures based on the answer for rebuilding the answer from scratch for the same question, more features will be helpful.\n",
    "Return a JSON object in this exact format:\n",
    "        {{\n",
    "            \"Analysis\": \"Analysis of the question, answer, and the features\",\n",
    "            \"Features\": [\n",
    "                {{\"feature\": \"string\", \"detail\": \"string\"}},\n",
    "                {{\"feature\": \"string\", \"detail\": \"string\"}},\n",
    "                ... and so on, until all features are covered.\n",
    "            ]\n",
    "        }}\n",
    "\"\"\"\n",
    "temperature = 0.0\n",
    "\n",
    "response_extract_features = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": \"You are an economics export and a knowledgeable teacher. Think concisely and precisely. If you meet difficulty, ask for clarification. pause and think deeply before you answer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_extract_features}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            # max_tokens=2000,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "gpt_answer_extract_features = response_extract_features.choices[0].message.content\n",
    "json_extract_features = json.loads(gpt_answer_extract_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random choice 3 feature\n",
    "random_features = random.sample(json_extract_features['Features'], k=3)\n",
    "print(random_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_swap_feature_p1 = f\"\"\"\n",
    "Task: For the selected feature, what is a misleading direction of the feature for the question. \\\n",
    "Modify or rewrite the feature to create a misleading feature. Keep other features the same.\n",
    "Question: {current_question['question']}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_swap_feature_p3 = f\"\"\"\n",
    "Return a JSON object in this exact format:\n",
    "        {{\n",
    "            \"analysis_1\": \"How the misleading feature can be created. Think step by step.\",\n",
    "            \"analysis_2\": \"Think deeper.\",\n",
    "            \"new_feature\": \"string\",\n",
    "            \"new_feature_detail\": \"string\",\n",
    "            \"old_feature\": \"string\",\n",
    "            ]\n",
    "        }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_feature_list = []\n",
    "\n",
    "count = 0\n",
    "for feature in random_features:\n",
    "    print(f'{count}th feature: {feature}')\n",
    "    count += 1\n",
    "    prompt_swap_feature_p2 = ''\n",
    "    prompt_swap_feature_p2 += f\"Selected Feature: {feature['feature']}. Description: {feature['detail']}\\n\"\n",
    "    # construct the prompt with the selected feature and the other unselected features\n",
    "    for other_feature in json_extract_features['Features']:\n",
    "        if feature['feature'] != other_feature['feature']:\n",
    "            prompt_swap_feature_p2 += f\"Other Feature: {other_feature['feature']}. Description: {other_feature['detail']}\\n\"\n",
    "\n",
    "    prompt_swap_feature = prompt_swap_feature_p1 + prompt_swap_feature_p2 + prompt_swap_feature_p3\n",
    "\n",
    "    response_swap_feature = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_swap_feature}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    gpt_answer_swap_feature = response_swap_feature.choices[0].message.content\n",
    "    swapped_feature_list.append(gpt_answer_swap_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = json.loads(swapped_feature_list[0])\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each swapped feature, find the corresponding feature in the original features, and swap the feature and detail\n",
    "new_features_list  = []\n",
    "\n",
    "for swapped_feature in swapped_feature_list:\n",
    "    new_feature = json.loads(swapped_feature)\n",
    "    # copy the original features\n",
    "    new_features = copy.deepcopy(json_extract_features['Features'])\n",
    "    for feature in new_features:\n",
    "        if feature['feature'] == new_feature['old_feature']:\n",
    "            feature['feature'] = new_feature['new_feature']\n",
    "            feature['detail'] = new_feature['new_feature_detail']\n",
    "    new_features_list.append(new_features)\n",
    "\n",
    "new_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each new_features, construct the prompt of the question with the new features\n",
    "\n",
    "prompt_generate_choice_p1 = f\"\"\"\n",
    "Features:\n",
    "\"\"\"\n",
    "\n",
    "prompt_generate_choice_p2 = f\"\"\"\n",
    "Task: Generate the answer for the given question with the given features, all of them are high level features and you need follow the directions\n",
    "Question: {current_question['question']}\n",
    "You do not need absolutely follow the directions, use the directions as a guide. aggregate the all the separate answers into a comprehensive answer in one paragraph. Do not need to do summary in the end.\n",
    "\"\"\"\n",
    "\n",
    "answer_list = []\n",
    "\n",
    "# generate the answer with the original features\n",
    "prompt_generate_choice = ''\n",
    "for temp in json_extract_features['Features']:\n",
    "    temp_str = f\"{temp['feature']}: {temp['detail']} \\n\"\n",
    "    prompt_generate_choice += temp_str\n",
    "prompt_generate_choice = prompt_generate_choice_p1 + prompt_generate_choice\n",
    "prompt_generate_choice = prompt_generate_choice + prompt_generate_choice_p2\n",
    "\n",
    "response_generate_choice = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_generate_choice}],\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "gpt_answer_generate_choice = response_generate_choice.choices[0].message.content\n",
    "answer_list.append(gpt_answer_generate_choice)\n",
    "\n",
    "# generate the answer with the new features\n",
    "for new_features in new_features_list:\n",
    "    prompt_generate_choice = ''\n",
    "    for temp in new_features:\n",
    "        temp_str = f\"{temp['feature']}: {temp['detail']} \\n\"\n",
    "        prompt_generate_choice += temp_str\n",
    "    prompt_generate_choice = prompt_generate_choice_p1 + prompt_generate_choice\n",
    "    prompt_generate_choice = prompt_generate_choice + prompt_generate_choice_p2\n",
    "    #print(prompt_generate_choice)\n",
    "    \n",
    "    # generate the answer\n",
    "    response_generate_choice = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_generate_choice}],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    gpt_answer_generate_choice = response_generate_choice.choices[0].message.content\n",
    "    print('==='*20)\n",
    "    print(gpt_answer_generate_choice)\n",
    "    answer_list.append(gpt_answer_generate_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "def shuffle_and_track_first_index(lst):\n",
    "    # Store the first element\n",
    "    first_element = lst[0]\n",
    "    \n",
    "    # Shuffle the list\n",
    "    random.shuffle(lst)\n",
    "    \n",
    "    # Find the new index of the original first element\n",
    "    new_index = lst.index(first_element)\n",
    "    \n",
    "    return lst, new_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_suffle_answer_list, new_index = shuffle_and_track_first_index(answer_list)\n",
    "\n",
    "print(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_question['question'])\n",
    "for i, c in enumerate('ABCD'):\n",
    "    print(f'{c}: {new_suffle_answer_list[i]}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec-10-k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
